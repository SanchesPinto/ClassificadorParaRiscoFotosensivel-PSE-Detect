
def train_looping(model, train_loader, val_loader, criterion, writer, device):
    # Filtra e passa para o Adam apenas os par√¢metros que est√£o "descongelados"
    params_to_update = filter(lambda p: p.requires_grad, model.parameters())
    optimizer = optim.Adam(params_to_update, lr=0.001)
    epochs = 10
    
    model.to(device) # Move o modelo para a GPU, se dispon√≠vel

    # --- NOVO: Vari√°vel para rastrear o melhor loss de valida√ß√£o ---
    best_val_loss = np.inf # Come√ßa com infinito, pois queremos o menor valor
    
    # --- MODIFICADO: Definimos o caminho e criamos a pasta ANTES do loop ---
    os.makedirs("models", exist_ok=True)
    best_model_path = "models/model2_best.pth" # Renomeei para "best" para clareza

    print(f"Iniciando treinamento... O melhor modelo ser√° salvo em: {best_model_path}")

    for epoch in range(epochs):
        model.train() # Modo de treinamento
        total_loss = 0
        correct_train = 0
        total_train = 0
        for X_batch, y_batch in train_loader:
            X_batch = X_batch.to(device)
            y_batch = y_batch.to(device).view(-1, 1) # <-- GARANTE O SHAPE (B, 1)
            
            optimizer.zero_grad()
            outputs = model(X_batch) # Sa√≠da s√£o logits
            loss = criterion(outputs, y_batch)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

            # Calcular acur√°cia de treino tamb√©m, para monitoramento
            probabilities = torch.sigmoid(outputs)
            predicted = (probabilities > 0.5).long()
            correct_train += (predicted == y_batch.long()).sum().item()
            total_train += y_batch.size(0)

        train_loss_avg = total_loss / len(train_loader)
        train_acc = correct_train / total_train

        val_loss, val_acc = avaliar_modelo(model, val_loader, criterion, device)
        
        print(f"√âpoca {epoch+1:02d}, "
              f"Loss Treino: {train_loss_avg:.4f}, Acur√°cia Treino: {train_acc*100:.2f}%, "
              f"Loss Val: {val_loss:.4f}, Acur√°cia Val: {val_acc*100:.2f}%")

        writer.add_scalars("Losses", {"Train": train_loss_avg, "Validation": val_loss}, epoch)
        writer.add_scalars("Accuracies", {"Train": train_acc, "Validation": val_acc}, epoch)

        # --- NOVO: L√≥gica para salvar o melhor modelo ---
        if val_loss < best_val_loss:
            best_val_loss = val_loss # Atualiza o melhor loss
            
            print(f"  ‚ú® Nova melhor pontua√ß√£o! Loss de Valida√ß√£o: {best_val_loss:.4f}. Salvando modelo...")
            
            # Salva o checkpoint (o estado atual do modelo)
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': best_val_loss,
            }, best_model_path)

    # --- MODIFICADO: Mensagem final ---
    print(f"\nTreinamento conclu√≠do.")
    print(f"üíæ O melhor modelo foi salvo em: {best_model_path} (com loss de {best_val_loss:.4f})")

    # Retorna o modelo (que est√° no estado da *√∫ltima* √©poca,
    # mas o *melhor* estado est√° salvo no arquivo)
    return model